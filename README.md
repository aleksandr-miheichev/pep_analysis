# Асинхронный парсер PEP

## Содержание
- [Описание проекта](#описание-проекта)
- [Технологический стек](#технологический-стек)
- [Как развернуть проект](#как-развернуть-проект)
- [Запуск](#запуск)
- [Над проектом работал](#над-проектом-работал)

___

### Описание проекта:

Парсер документов PEP на базе фреймворка Scrapy. Парсер выводит собранную 
информацию в два файла .csv:
- в первый файл - список всех PEP: номер, название и статус;
- во второй файл - сводку по статусам PEP — сколько найдено документов в 
каждом статусе (статус, количество), а в последней строке этого файла — общее 
количество всех документов.

___

### Технологический стек:

- [![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)](https://www.python.org/)
- [Scrapy](https://scrapy.org/)

___

### Как развернуть проект:

Клонировать репозиторий и перейти в него в командной строке используя команду 
```
cd
```
```bash
git clone git@github.com:aleksandr-miheichev/scrapy_parser_pep.git
```
Cоздать и активировать виртуальное окружение:
```bash
python -m venv venv
```
```bash
source venv/Scripts/activate
```
Установить зависимости из файла requirements.txt:
```bash
pip install -r requirements.txt
```

___

### Запуск

Чтобы запустить паука необходимо в командной строке использовать команду
```bash
scrapy crawl pep
```

___

### Над проектом работал:
- [Михеичев Александр](https://github.com/aleksandr-miheichev)
